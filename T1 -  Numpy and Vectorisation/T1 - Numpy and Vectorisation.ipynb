{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python & Numpy #\n",
    "\n",
    "Objectives: get familiar with some important aspects of Python 3 and in particular see how to replace python loops with vectorised operations using the numpy library.\n",
    "\n",
    "> **Instructions:** <br>\n",
    "> - Ensure your Python environment is setup correctly, in particular Jupyter package is installed.<br>As we progress through this module, you may be required to install additional packages.\n",
    "> - Prior to this tutorial, read the entire notebook and attempt all coding exercises.\n",
    "> - To complete the coding exercises, write some python code between<br>`### INPUT YOUR CODE HERE ###` and `### END OF YOUR CODE SEGMENT ###`.<br> We will generally provide a rough estimate of the number of lines to write.\n",
    "? - Run cells by pressing `Shift+Enter` and verify that your results are consistent with unit tests.\n",
    "\n",
    "Upon completion of this tutorial, you ought to be familiar with vectorisation in numpy.\n",
    "\n",
    "> <font color='darkgreen'>**Exercise 1:**</font> Test your Python 3 runtime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## A. Numpy ##\n",
    "\n",
    "[Numpy](http://www.numpy.org) is an optimised and well maintained scientific computing package for Python. Most math functions have numpy equivalents that accept arrays as input, for example `np.exp(.)` is the numpy equivalent of `math.exp(.)`. You will now implement a function to apply the sigmoid function $\\sigma(x) = \\frac{1}{1+e^{-x}}$ to an array of scalars. This symmetric function is highly non-linear and maps scalar values to the interval (0,1). It is also referred to as the logistic function and is frequently used in machine learning and deep learning. You will use it in the next tutorial to carry out a simple regression classification task on images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $x=(x_1, x_2, \\dots, x_n)$ be a row vector then `np.exp(x)` will apply the exponential function to every element of $x$, with the resulting vector $(e^{x_1}, e^{x_2}, \\ldots, e^{x_n})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.   2.72 7.39]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "x = np.array([0, 1, 2])\n",
    "print(np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, if $x$ is a vector then a Python operation such as $\\frac{1}{2 x + 1}$ will output a vector of the same size as $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.   2. -10.]\n"
     ]
    }
   ],
   "source": [
    "# numpy vector operation\n",
    "x = np.array([0, 0.2, -0.1])\n",
    "print(1 / (2 * x + 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='darkgreen'>**Exercise 2:**</font> Implement the sigmoid function using numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # for easy access to numpy functions\n",
    "\n",
    "# Sigmoid vectorial function\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of x\n",
    "\n",
    "    Arguments:\n",
    "    x -- scalar or numpy array of any size\n",
    "\n",
    "    Returns:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INPUT YOUR CODE HERE ### (1 line)\n",
    "    s=1/(1+np.exp(-x))\n",
    "    ### END OF YOUR CODE SEGMENT ###  \n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5 , 0.73, 0.88])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([0, 1, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Expected Output:***\n",
    ">\n",
    "> `array([0.5 , 0.73, 0.88])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXzV9Z3v8dfn5GQnIUBYQyCgLIIVsWFxaavi2rq0nVaxarVaaWeq1ba3t7be2tZ5zEynnU6nM7WLo1YrKrjVMh1cq7ZurIILm0YgJOwQIIHsOZ/7xznQYwxwgJP8zjl5Px8PHmf7cs4bOXn74/tbvubuiIhI+gsFHUBERJJDhS4ikiFU6CIiGUKFLiKSIVToIiIZQoUuIpIhVOiSlszse2Z2d6p9rpmtN7Nz4h5PMLMlBxk72MxWmVlud2SV3sd0HLpI8pjZeuDL7v587PHjwKPuPucg438FrHL3/+q5lJKptIUu0k3MbChwFvDkIYY9CHylZxJJplOhS8ozs++Y2UYzazCzNWY2w8x+aGaz48Z80cyqzWynmX0/fuojNvZRM5sde4+3zWysmX3XzLaZWY2ZnRf3XsPMbJ6Z1ZlZlZndEPda58+9Ou5zb+sU/VzgDXdvPsQfbyEw2sxGHut/JxEVuqQ0MxsH3AhMcfci4HxgfacxE4BfAVcCQ4G+QFmnt7oYeADoBywDniH6/S8D7gB+Gzf2YaAWGAZ8DvhnM5vRRbYJwK+Bq2NjBwDD44Z8BFhzqD+fu7cDVcCkQ40TSYQKXVJdB5ALTDCzbHdf7+7vdxrzOeB/3P0Vd28Fbgc67xx62d2fiRXoo8BA4Mfu3gbMASrMrMTMyoEzgO+4e7O7LwfuJlranX0O+JO7/9XdW4DvA5G410uAhgT+jA2xsSLHRIUuKc3dq4BbgB8C28xsjpkN6zRsGFAT93sagZ2dxmyNu98E7HD3jrjHAH1i71Xn7vFFXM2Ht/i7+tx9nT53F1B00D/c3xQBuxMYJ3JIKnRJee7+kLufAYwkuuX9r52GbCZuqsPM8olOfxyNTUB/M4sv4hHAxi7GbgbK4z63oNPnvgWMPdSHmVkYOB548yjzihygQpeUZmbjzOzs2LHazUS3pjs6DXsMuNjMTjOzHOBHgB3N57l7DfAa8C9mlmdmJwHXEz0apbPHgIvM7IzY597BB3+mngNOMbO8Q3zkVGC9u1cfTV6ReCp0SXW5wI+BHcAWYBDwvfgB7r4CuInoXPhmonPS24CWo/zMK4AKolvrfwB+4O7PdR4U+9yvAQ/FPncX0Z2p+1/fCrwAXLr/OTN7yszi818J/OYoc4p8gE4skoxjZn2IzkmPcfd1AWeZANwPTPVOP2xmNgj4CzD5MIc2iiREhS4ZwcwuBv5MdKrlZ8A04JTOJSqSyTTlIpniUqJTJJuAMcBMlbn0NtpCFxHJENpCFxHJEOGgPri0tNQrKiqC+ngRkbS0dOnSHe4+sKvXAiv0iooKlizp8jLRIiJyEGZ20HMWNOUiIpIhVOgiIhlChS4ikiFU6CIiGUKFLiKSIQ5b6GZ2b2yZrncO8rqZ2X/Glup6y8xOSX5MERE5nES20O8DLjjE6xcSPdV6DDCL6JJcIiLSww57HLq7/9XMKg4x5FLg97HrZiyILeM11N03JymjiMgRcXfaOpzWjggtbR20dkRobY/96ojQEfEP/3KnPeJEItHbw41xdyIeXXHF3XGHiDtO7NbjnwcnOh53ZpwwmEnlyV91MBknFpURtwwX0etBlxG9PvQHmNksolvxjBgxIgkfLSKZoqm1g12NrdTta2V3Yxt1ja3UN7Wxr6Wdfa0d7Gtpp7G1nb0t0fvR59tpbOmgpT1CS3v0dn9pp+plqsxgcN+8lC30rlaG6fI/pbvfBdwFUFlZmaL/uUUkmZrbOqipa2TTnma27Gliy54WttQ3sWVPM1vrW9jV2Mquxlaa2yKHfJ/CnCwKcsP0yQ1TmJtFQU6YQUV55A/IIi+cRW52iJysELnh6K+c2K/ccFb0flaI3OwQ4VCIcMjIyjKyzAiHjFCo060Z4ay4+6EQoRAHbrMs+rwZWOw2ZIZB3PNgGKHYmP233SkZhV5L3LqKRNd23JSE9xWRNLKtvpkVm+qp2raXdTv3sX5H9Nfm+uYPbS2X9slhSN88hvbNY8KwYvoX5lBSkE3/ghxKCnLoX5hDv4Js+uZnU5gbJj87i1Coe8swEySj0OcBN5rZHKKLCuzR/LlIZtu0u4llG3azYtMeVmyqZ8Wmenbs/duKfyUF2VQMKGTa6AFUDCikorSAspJ8BhfnMbg4j5ywjpjuDoctdDN7GDgTKDWzWuAHQDaAu/8GmA98EqgCGoEvdVdYEQnG5j1NvPzuDhauq2Phup3U7moCIBwyxgwu4sxxA5k4rJiJw/oydnAfSgpyAk7cOyVylMsVh3ndiS6UKyIZIhJxltfu5oVV2/jz6m2s2lwPQP/CHKZW9Oe600dRWdGPcUOKyA1nBZxW9gvs8rkiknrWbGngyeUbmbd8Ext3N5EVMj46sh+3XjieM8cNZNzgom7fsSdHT4Uu0ss1tXbw5PKNPPB6NSs315MVMs44vpRvnTeWGeMH07cgO+iIkiAVukgvVVPXyAMLqpm7uIY9TW2MH1LEDy+ewKdOGsbAotyg48lRUKGL9DIbdzfxyxfe49EltThwwcQhXHNaBVMq+mk6Jc2p0EV6iW31zfzyxSrmLIqe2P2FaSP46ieOY1hJfsDJJFlU6CIZrr0jwv2vV/Pz596lua2Dz1cO58azx1CmIs84KnSRDLa0uo7b/vAOq7c08ImxA/nRJROpKC0MOpZ0ExW6SAZqbuvgx0+t5r7X1jO0bx6/ueoUzp84RHPkGU6FLpJh3tvawE0PL2P1lgauPa2Cb58/jsJc/aj3BvpbFskQ7s6cxTX86H9WUJgT5ndfmsJZ4wYFHUt6kApdJAO0tke47Q9v8+jSWj42ppSfXTaJQUV5QceSHqZCF0lzexrb+Orspby+didfnzGGW2aM0aVmeykVukga27CzkS/dt4gNdY38+2WT+Owpw4OOJAFSoYukqXc27uGL9y4i4s7s66cxbfSAoCNJwFToImloxaY9XHXPQgpzwjxw/VRGD+wTdCRJASp0kTSzclM9V969kILsLB6+YTojBhQEHUlShNaBEkkj0TJfQH52Fg/PUpnLB6nQRdLE+h37uOqeheRlZzFn1nRGDtAp/PJBKnSRNLC7sZXr7luMu/PQDSpz6Zrm0EVSXGt7hK/OXkrtriZmf3kao3RxLTkIFbpICnN3vvvE2yxYW8fPL5/E1FH9g44kKUxTLiIp7Fcvvc/jb9Ry84wxfGayThqSQ1Ohi6SoV6t28G/PruGSScO45ZwxQceRNKBCF0lB2xtauGXuckaXFvLjv/uIrmMuCdEcukiKiUScbz6ynPqmNn5/3VQKcvRjKonRFrpIivnNX9/n5fd28IOLJ3LC0OKg40gaUaGLpJCl1XX87Nl3+dRJQ7liannQcSTNqNBFUkRTawffmPsmZSX5/MtnNW8uR06TcyIp4mfPrmFDXSNzZk2nOC876DiShrSFLpIClm3Yxb2vruPKaSOYruuay1FSoYsErLU9wncef4vBxXnceuH4oONIGkuo0M3sAjNbY2ZVZnZrF6+PMLMXzWyZmb1lZp9MflSRzPSrl6p4d+te/ukzJ1KkqRY5BoctdDPLAu4ELgQmAFeY2YROw/4f8Ii7TwZmAr9KdlCRTLRmSwN3vljFp08extnjBwcdR9JcIlvoU4Eqd1/r7q3AHODSTmMc2H/AbF9gU/IiimQmd+f7f3yHPrlhbr94YtBxJAMkUuhlQE3c49rYc/F+CFxlZrXAfOCmrt7IzGaZ2RIzW7J9+/ajiCuSOZ56ZwuL1tXxrfPG0b8wJ+g4kgESKfSuDob1To+vAO5z9+HAJ4EHzOxD7+3ud7l7pbtXDhw48MjTimSI5rYO/nn+KsYPKWLmFJ1AJMmRSKHXAvHfuOF8eErleuARAHd/HcgDSpMRUCQT3fPKOmp3NXH7RRMIZ+lgM0mORL5Ji4ExZjbKzHKI7vSc12nMBmAGgJmdQLTQNaci0oWt9c3c+WIV508czGnHa7tHkuewhe7u7cCNwDPAKqJHs6wwszvM7JLYsG8BN5jZm8DDwLXu3nlaRkSAnzy9hvYO57ZPdj5YTOTYJHTqv7vPJ7qzM/652+PurwROT240kczzdu0eHn+jlq9+4jhGDCgIOo5kGE3eifSgnzyzmv6FOXztrOOCjiIZSIUu0kMWrt3Jy+/t4O8/cZzOCJVuoUIX6QHuzs+efZdBRblcNX1k0HEkQ6nQRXrAK1U7WLS+jhvPPp78nKyg40iGUqGLdDN359+eWUNZST6X6yQi6UYqdJFu9vyqbbxZu4ebZ4whN6ytc+k+KnSRbhSJOD97dg2jSgv57CmdL4EkklwqdJFu9OzKraze0sAt54zRKf7S7fQNE+km7s6vX6pi5IACPvWRoUHHkV5AhS7STV57fydv1u7hKx8/Tlvn0iP0LRPpJr9+6X0GFuVq7lx6jApdpBu8VbubV6p28OUzRpGXrSNbpGeo0EW6wa9efJ/ivDBfmDYi6CjSi6jQRZKsattenlm5hS+eWqFrtkiPUqGLJNlv//I+OVkhrj29Iugo0suo0EWSaGt9M08u38jlU8op7ZMbdBzpZVToIkk0e0E17RHn+jNGBR1FeiEVukiSNLd18ODCDcwYP5iRAwqDjiO9kApdJEn+uHwjdftaue6MiqCjSC+lQhdJAnfn3lfWM35IEaeOHhB0HOmlVOgiSfD6+ztZs7WB684YhZkFHUd6KRW6SBLc++o6BhTmcMmkYUFHkV5MhS5yjNbt2MefV2/jymkjdJq/BEqFLnKM7n9tPeGQafFnCZwKXeQY7G1p57GltVx00jAGFecFHUd6ORW6yDF4ctlG9ra0c/Wp2jqX4KnQRY6SuzN7QTUThhYzubwk6DgiKnSRo7W0ehertzRw9akjdaiipAQVushRmr2gmqLcMJeerEMVJTWo0EWOws69Lcx/ewt/99HhFOSEg44jAiRY6GZ2gZmtMbMqM7v1IGMuM7OVZrbCzB5KbkyR1PLIklpaOyJcqRWJJIUcdtPCzLKAO4FzgVpgsZnNc/eVcWPGAN8FTnf3XWY2qLsCiwStI+I8tKia6aP7M2ZwUdBxRA5IZAt9KlDl7mvdvRWYA1zaacwNwJ3uvgvA3bclN6ZI6vjru9upqWvSiUSSchIp9DKgJu5xbey5eGOBsWb2qpktMLMLunojM5tlZkvMbMn27duPLrFIwB5cWE1pn1zOmzAk6CgiH5BIoXd1PJZ3ehwGxgBnAlcAd5vZhw7Mdfe73L3S3SsHDhx4pFlFArdlTzMvrN7GZZXDyQnrmAJJLYl8I2uB8rjHw4FNXYz5o7u3ufs6YA3RghfJKI+/UUvE4bLK8sMPFulhiRT6YmCMmY0ysxxgJjCv05gngbMAzKyU6BTM2mQGFQlaJOLMXVzDqaMHUFGqJeYk9Ry20N29HbgReAZYBTzi7ivM7A4zuyQ27Blgp5mtBF4Evu3uO7srtEgQFqzdyYa6RmZO1da5pKaEzohw9/nA/E7P3R5334Fvxn6JZKQ5i2vom5/N+RO1M1RSk/bqiCRg175Wnn5nC5+ZXKZFLCRlqdBFEvDk8o20dkS4fIqmWyR1qdBFDsPdmbOohknlJZwwtDjoOCIHpUIXOYzlNbtZs7WBmdo6lxSnQhc5jLmLayjIyeLiSbpMrqQ2FbrIIextaWfem5u46KSh9MnVZXIltanQRQ7hf9/aRGNrB5dP0WVyJfWp0EUOYc7iGsYM6sMpI7RmqKQ+FbrIQazZ0sCyDbu5fEq51gyVtKBCFzmIuYtryM4yPnvK8KCjiCREhS7ShZb2Dp5YVst5E4fQvzAn6DgiCVGhi3Th2RVb2d3YpmPPJa2o0EW6MHdxDWUl+Zx+XGnQUUQSpkIX6WTDzkZeqdrB5VPKCYW0M1TShwpdpJNHltQQMvh8pXaGSnpRoYvEae+I8OjSGs4cN4ihffODjiNyRFToInH+8u52tta36DK5kpZU6CJx5iyuobRPLmePHxR0FJEjpkIXidlW38wLq7fxuY8OJztLPxqSfvStFYl57I1aOiKu6RZJWyp0EaKrEs1dXMO0Uf0ZVVoYdByRo6JCFwEWrK2jemcjM6dq61zSlwpdBJi7eANFeWEuPHFo0FFEjpoKXXq93Y2tzH9nC5+ZXEZedlbQcUSOmgpder0n3thIa3tEO0Ml7anQpVdzdx5etIFJ5SVMHNY36Dgix0SFLr3a0updvLdtL1dO1Zqhkv5U6NKrPbRwA31yw1w0STtDJf2p0KXX2t3Yyp/e3synJw+jICccdByRY6ZCl17rD8uiO0O/MHVk0FFEkkKFLr2Su/PQwujO0AnDioOOI5IUCRW6mV1gZmvMrMrMbj3EuM+ZmZtZZfIiiiTf/p2hX9CZoZJBDlvoZpYF3AlcCEwArjCzCV2MKwK+DixMdkiRZHtoUXRn6MWThgUdRSRpEtlCnwpUuftad28F5gCXdjHuH4GfAM1JzCeSdHsa2/jft7QzVDJPIoVeBtTEPa6NPXeAmU0Gyt39T4d6IzObZWZLzGzJ9u3bjzisSDI8sayWlvYIV+jYc8kwiRR6V8ue+4EXzULAz4FvHe6N3P0ud69098qBAwcmnlIkSXRmqGSyRAq9FojfczQc2BT3uAg4EXjJzNYD04F52jEqqWhp9S7e3aqdoZKZEin0xcAYMxtlZjnATGDe/hfdfY+7l7p7hbtXAAuAS9x9SbckFjkG+3eGXnSSdoZK5jlsobt7O3Aj8AywCnjE3VeY2R1mdkl3BxRJll37Wg/sDC3M1c5QyTwJfavdfT4wv9Nztx9k7JnHHksk+eYsrqGlPcLV0yuCjiLSLXSmqPQKHRFn9oJqTh09gHFDioKOI9ItVOjSK/x51VY27m7imtN03RbJXCp06RXuf309w/rmcc4Jg4OOItJtVOiS8aq2NfBq1U6unD6ScJa+8pK59O2WjHf/a9XkhEPM1JqhkuFU6JLR6pvbePyNWi4+aRgD+uQGHUekW6nQJaM9sbSWxtYO7QyVXkGFLhmrI+Lc99p6Ti4v4aThJUHHEel2KnTJWM+t3Mr6nY3c8LHRQUcR6REqdMlY//3yWsr753P+RB2qKL2DCl0y0tLqXSyt3sX1p4/SoYrSa+ibLhnp7pfX0jc/m89X6lBF6T1U6JJxqnfu4+kVW7hy2ghdVVF6FRW6ZJx7XllHOGRce1pF0FFEepQKXTLKrn2tPLKkhk+fXMag4ryg44j0KBW6ZJQHFlTT3Bbhho/rUEXpfVTokjH2trRzzyvrmDF+EGMH65rn0vuo0CVj/P719expauPrM8YEHUUkECp0yQj7Wtq5++V1nDluIJPKdZq/9E4qdMkIDy6spm5fKzedra1z6b1U6JL2mlo7uOuva/nYmFI+OrJf0HFEAqNCl7T30KIN7Njbqrlz6fVU6JLWmts6+M1f3ufU0QOYUtE/6DgigVKhS1p7cOEGtje0cNOM44OOIhI4FbqkrfrmNn75wnuccXwppx1XGnQckcCp0CVt/eal99nV2MatF44POopISlChS1ravKeJe15Zx6dPHsaJZX2DjiOSElTokpZ+/ty7uMO3zhsXdBSRlKFCl7Tz7tYGHltayxdPHUl5/4Kg44ikDBW6pJ1/fWo1hblhvnaWjmwRiZdQoZvZBWa2xsyqzOzWLl7/ppmtNLO3zOzPZjYy+VFF4JX3dvDn1dv4hzOPp19hTtBxRFLKYQvdzLKAO4ELgQnAFWY2odOwZUClu58EPAb8JNlBRVraO7j9j+9QMaCAL51eEXQckZSTyBb6VKDK3de6eyswB7g0foC7v+jujbGHC4DhyY0pAv/917Ws3bGPOy49kbzsrKDjiKScRAq9DKiJe1wbe+5grgee6uoFM5tlZkvMbMn27dsTTym9Xk1dI//1QhWf+shQPj52YNBxRFJSIoVuXTznXQ40uwqoBH7a1evufpe7V7p75cCB+qGUxLg7P5i3gnDI+P5FnWf7RGS/RAq9FiiPezwc2NR5kJmdA9wGXOLuLcmJJwLPrdzKC6u38Y1zxzKkrxZ+FjmYRAp9MTDGzEaZWQ4wE5gXP8DMJgO/JVrm25IfU3qrhuY2fvQ/Kxk/pIhrTqsIOo5ISjtsobt7O3Aj8AywCnjE3VeY2R1mdkls2E+BPsCjZrbczOYd5O1Ejsg//mklm/c08U+f+QjZWTptQuRQwokMcvf5wPxOz90ed/+cJOcS4dkVW3hkSS1fO+s4rUQkkgBt8khK2rG3he8+8TYThxVz84yxQccRSQsJbaGL9CR359bH36ahpZ2HLz+ZnLC2O0QSoZ8USTmPLqnl+VVb+b/nj2Ps4KKg44ikDRW6pJTVW+r5wbwVTB/dn+tOHxV0HJG0okKXlLGnsY2vPLCUorww/zlzMqFQV+e0icjBaA5dUkJHxLl57jI27W5izqzpDCrWCUQiR0pb6JIS/uP5d3lpzXZ+cPFEPjqyf9BxRNKSCl0C9/Q7W/ivF6q4rHI4V04bEXQckbSlQpdALV5fx81zljGpvIQ7Lj0RM82bixwtFboEZtXmeq67bzFlJfnce02lrnEucoxU6BKI6p37+OK9i+iTG+aBL09jQJ/coCOJpD0VuvS4bfXNXH3PIto6Ijxw/VTKSvKDjiSSEVTo0qNq6hq57Levs2NvC7+7dgrHD9KZoCLJouPQpce8t7WBq+5ZSFNrBw9cP43JI3QFRZFkUqFLj1hes5trf7eI7KwQj3z1VMYPKQ46kkjGUaFLt3th9VZuemgZ/fvkMPv6aYwcUBh0JJGMpEKXbhOJOP/5wnv8x/PvMXFYMfdeO4XBOqVfpNuo0KVb7Glq4xtzl/PC6m383SnD+afPnKjjzEW6mQpdku6NDbv4xtzlbNzVxD9eOpGrpo/UGaAiPUCFLknT3NbBvz/3Lne/vJahffOZM2s6lRW60JZIT1GhS1Isra7j24+9xdrt+/jCtBF875Mn0CdXXy+RnqSfODkmG3c38dOnV/Pk8k2UleQz+/ppnDGmNOhYIr2SCl2Oyt6Wdn79UhV3v7wOB/7hzOP4h7OO11a5SID00ydHpG5fK/e/tp77X1/P7sY2Pn3yML59wXhdj0UkBajQJSE1dY3c88o65i6uoamtg3NOGMxNZx/PpPKSoKOJSIwKXQ6qua2DZ1duZe7iDbxatZNwyPj05DK+8vHRjBmsi2qJpBoVunxAW0eE197fydPvbOapd7awu7GNspJ8vnnuWD5fOZyhfTW1IpKqVOjCjr0tvPb+Tl5as43nV26lvrmdwpwsZpwwmMsqyzntuAGEQjoxSCTVqdB7oW31zbyxYTdLq+t4tWonKzfXA9A3P5tzJwzhwhOHcMaYUp2qL5JmVOgZLBJxanY1smZLA2u2NLB6awPLN+xm4+4mAHKyQpwysoRvnz+OM44v5cSyvmRpS1wkbanQ01wk4mxtaKamromaukY21DVSs6uR97fv472tDTS2dhwYW94/n5PLS/jS6RVMHtGPE8uKyQ1rK1wkUyRU6GZ2AfALIAu4291/3On1XOD3wEeBncDl7r4+uVF7B3enpT1CfVMb9c1t7GlqY3tDKzv2trC9oYXt+2/jfrV2RA78fjMYWpxHRWkhl08pZ9zgIsYNKWLs4CIKddKPSEY77E+4mWUBdwLnArXAYjOb5+4r44ZdD+xy9+PNbCbwr8Dl3RG4O7k7EYeIOx677Yg4bR0R2jqit+0dTlskcuB+6/7nOiIHxrV3RGiN3W9q66CptZ2m1sjf7rd10NQWOXB/b0sHDbECr29q/0BBxzOD/gU5DCzKZWBRLqNLCxlYnEt5vwLK+xcwon8Bw0rytNUt0kslssk2Fahy97UAZjYHuBSIL/RLgR/G7j8G/NLMzN09iVkBeGRxDXe9vPYDpRtxJxL5YCFHfP9jx4lOTXjcax/6/UlP+mE5WSHyc7LIz876wG1xXpjyfvkU52dTnJdNcX44dptNcV6Y0j65DCrKpX9hDuEsrestIl1LpNDLgJq4x7XAtIONcfd2M9sDDAB2xA8ys1nALIARI0YcVeB+hTmMG1yEGYTMCMVuLe5+KMSBx0bs1uxv40N2yN9v/G1MlhnZWSGys6K34bj70cdGTlaIcMjIDofIDoXIDhvhUIicrBB5OSEKcsLkhUMqYxHpVokUeleHPXTenk1kDO5+F3AXQGVl5VFtE587YTDnThh8NL9VRCSjJbLJWAuUxz0eDmw62BgzCwN9gbpkBBQRkcQkUuiLgTFmNsrMcoCZwLxOY+YB18Tufw54oTvmz0VE5OAOO+USmxO/EXiG6GGL97r7CjO7A1ji7vOAe4AHzKyK6Jb5zO4MLSIiH5bQgcnuPh+Y3+m52+PuNwOfT240ERE5EjrsQkQkQ6jQRUQyhApdRCRDqNBFRDKEBXV0oZltB6qP8reX0uks1BSSqtmU68ikai5I3WzKdeSOJttIdx/Y1QuBFfqxMLMl7l4ZdI6upGo25ToyqZoLUjebch25ZGfTlIuISIZQoYuIZIh0LfS7gg5wCKmaTbmOTKrmgtTNplxHLqnZ0nIOXUREPixdt9BFRKQTFbqISIZI20I3s5PNbIGZLTezJWY2NehM+5nZTWa2xsxWmNlPgs7TmZn9HzNzMysNOguAmf3UzFab2Vtm9gczKwk4zwWxv78qM7s1yCz7mVm5mb1oZqti36ubg84Uz8yyzGyZmf0p6CzxzKzEzB6Lfb9WmdmpQWcCMLNvxP4e3zGzh80sLxnvm7aFDvwE+JG7nwzcHnscODM7i+gaqye5+0Tg3wKO9AFmVk50we8NQWeJ8xxworufBLwLfDeoIHGLol8ITACuMLMJQeWJ0w58y91PAKYDX0uRXPvdDKwKOkQXfgE87e7jgUmkQEYzKwO+DlS6+4lEL0uelEuOp3OhO1Acu9+XD6+iFJS/B37s7i0A7r4t4Dyd/Rz4v3SxRGBQ3P1Zd2+PPVxAdFWsoBxYFN3dW5TThBUAAALESURBVIH9i6IHyt03u/sbsfsNRIupLNhUUWY2HPgUcHfQWeKZWTHwcaLrNeDure6+O9hUB4SB/NgKbwUkqb/SudBvAX5qZjVEt4ID26rrZCzwMTNbaGZ/MbMpQQfaz8wuATa6+5tBZzmE64CnAvz8rhZFT4ni3M/MKoDJwMJgkxzwH0Q3EiJBB+lkNLAd+F1sOuhuMysMOpS7byTaWRuAzcAed382Ge+d0AIXQTGz54EhXbx0GzAD+Ia7P25mlxH9v/A5KZArDPQj+s/iKcAjZja6p5bkO0y27wHn9USOzg6Vy93/GBtzG9GphQd7MlsnCS14HhQz6wM8Dtzi7vUpkOciYJu7LzWzM4PO00kYOAW4yd0XmtkvgFuB7wcZysz6Ef1X3yhgN/ComV3l7rOP9b1TutDd/aAFbWa/JzpvB/AoPfjPvcPk+nvgiViBLzKzCNEL8GwPMpuZfYToF+hNM4PotMYbZjbV3bcElSsu3zXARcCMgNejTWRR9ECYWTbRMn/Q3Z8IOk/M6cAlZvZJIA8oNrPZ7n5VwLkg+ndZ6+77/yXzGNFCD9o5wDp33w5gZk8ApwHHXOjpPOWyCfhE7P7ZwHsBZon3JNE8mNlYIIcUuNKbu7/t7oPcvcLdK4h+2U/piTI/HDO7APgOcIm7NwYcJ5FF0XucRf8vfA+wyt3/Peg8+7n7d919eOw7NZPoAvGpUObEvts1ZjYu9tQMYGWAkfbbAEw3s4LY3+sMkrSzNqW30A/jBuAXsZ0KzcCsgPPsdy9wr5m9A7QC1wS8xZkOfgnkAs/F/vWwwN2/GkSQgy2KHkSWTk4HrgbeNrPlsee+F1vvVw7uJuDB2P+c1wJfCjgPsemfx4A3iE4xLiNJlwDQqf8iIhkinadcREQkjgpdRCRDqNBFRDKECl1EJEOo0EVEMoQKXUQkQ6jQRUQyxP8HvvyL5hsXLYEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "x = np.arange(-8, 8, 0.1)\n",
    "plt.plot(x,sigmoid(x))\n",
    "_ = plt.title('sigmoid(.)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimisation of loss functions using back-propagation requires the computation of gradients. This is the backbone of a training process in deep learning. \n",
    "\n",
    "> <font color='darkgreen'>**Exercise 3:**</font> Let's now code the gradient function for the sigmoid map given by $\\frac{d}{dx} \\sigma(x) =\\sigma'(x) = \\sigma(x) (1 - \\sigma(x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def grad_sigmoid(x):\n",
    "    \"\"\"\n",
    "    Compute the gradient of the sigmoid function with respect to its input x\n",
    "    \n",
    "    Arguments:\n",
    "    x -- A scalar or numpy array\n",
    "\n",
    "    Returns:\n",
    "    ds -- Your computed gradient\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INPUT YOUR CODE HERE ### (2 lines)\n",
    "    s = sigmoid(x)\n",
    "    ds = s*(1-s)\n",
    "    ### END OF YOUR CODE SEGMENT ###  \n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_sigmoid = [0.2  0.1  0.05]\n"
     ]
    }
   ],
   "source": [
    "print(\"grad_sigmoid = \" + str(grad_sigmoid(np.array([1, 2, 3]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Expected Output:***\n",
    ">\n",
    "> `grad_sigmoid = [0.2  0.1  0.05]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(-8, 8, 0.1)\n",
    "plt.plot(x,grad_sigmoid(x),'-')\n",
    "_ = plt.title('sigmoid\\'(.)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### A.1 Reshaping Arrays ###\n",
    "\n",
    "Another very common operation in deep learning is the manipulation of arrays. For example, converting a tensor input of dimension $(W,H,D)$ to a column vector of size $(W\\times H\\times D, 1)$. Such unrolling operation is very frequent and referred to as reshaping. Numpy provides two useful functions for these tasks:\n",
    "\n",
    "- `np.shape`: to query the dimension\n",
    "- `np.reshape()`: to reinterpret array with different dimensions\n",
    "\n",
    "<img src=\"figs/reshape.png\" alt=\"Image Reshape\" width=\"500\"/>\n",
    "\n",
    "An image is typically represented as a 3D tensor of shape $(W,H,D)$ which may need to be rearranged as vector of $(W\\times H\\times D, 1)$ elements.\n",
    "\n",
    "> <font color='darkgreen'>**Exercise 4:**</font> Implement the function `im2vec()` that takes an input of shape $(W, H, 3)$ and returns a column vector of shape $(W\\times H\\times 3,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def im2vec(image):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    image -- a numpy array of shape (W, H, D)\n",
    "    \n",
    "    Returns:\n",
    "    v -- a column vector of shape (W*H*D, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INPUT YOUR CODE HERE ### (1 line)\n",
    "    \n",
    "    v=image.reshape(image.shape[0]*image.shape[1] *image.shape[2], 1)\n",
    "    ### END OF YOUR CODE SEGMENT ###  \n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.shape = (2, 2, 3)\n",
      "im2vec(image).shape = (12, 1)\n",
      "im2vec(image).T = [[0.2 0.1 0.8 0.8 0.7 0.5 0.4 0.2 0.7 0.5 0.3 0.2]]\n"
     ]
    }
   ],
   "source": [
    "# 2x2 RGB image\n",
    "image = np.array([\n",
    "    [[ 0.2, 0.1, 0.8],\n",
    "     [ 0.8, 0.7, 0.5]],\n",
    "    \n",
    "    [[ 0.4, 0.2, 0.7],\n",
    "     [ 0.5, 0.3, 0.2]]])\n",
    "\n",
    "print(\"image.shape = {}\".format(image.shape))\n",
    "print(\"im2vec(image).shape = {}\".format(im2vec(image).shape))\n",
    "print(\"im2vec(image).T = {}\".format(im2vec(image).T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Expected Output:***\n",
    ">\n",
    "> `image.shape = (2, 2, 3)\n",
    "im2vec(image).shape = (12, 1)\n",
    "im2vec(image).T = [[0.2 0.1 0.8 0.8 0.7 0.5 0.4 0.2 0.7 0.5 0.3 0.2]]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### A.2 Normalisation of Data ###\n",
    "\n",
    "Normalisation of data is an important pre-processing step in deep learning. It often yields better performance with faster algorithm convergence and better optimisation results. A typical strategy consists in setting input vectors to unit value. Given an input vector $x$, the normalised vector is given by $\\frac{x}{\\|x\\|}$.\n",
    "\n",
    "If your data samples are organised as row or column entries in a matrix, you can use `np.linalg.norm(.)` and specify the axis along which you want to compute the norm. For example:\n",
    "\n",
    "$$\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "    1 & 2 & 3 \\\\\n",
    "    4 & 5 & 6\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "then \n",
    "\n",
    "$$\n",
    "\\|X\\| = \n",
    "\\mbox{np.linalg.norm(X, axis=1, keepdims=True)} = \\begin{bmatrix}\n",
    "    \\sqrt{15} \\\\\n",
    "    \\sqrt{77} \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "X'=\\frac{X}{\\|X\\|}=\\begin{bmatrix}\n",
    "    \\frac{1}{\\sqrt{15}} & \\frac{2}{\\sqrt{15}} & \\frac{3}{\\sqrt{15}} \\\\\n",
    "    \\frac{4}{\\sqrt{77}} & \\frac{5}{\\sqrt{77}} & \\frac{6}{\\sqrt{77}}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Note that although $X$ is a $2\\times 3$ matrix and $\\| X\\|$ is $2\\times 1$,\n",
    "numpy permits the division of $X$ by $\\| X\\|$ using a mechanism called [broadcasting](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html). It is useful when performing operations between arrays of different shapes.\n",
    "\n",
    "> <font color='darkgreen'>**Exercise 5:**</font> Implement `normalise()` such that each row of the input X are unit length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def normalise(X):\n",
    "    \"\"\"\n",
    "    Normalises each row of the matrix X to unit length\n",
    "    \n",
    "    Argument:\n",
    "    X -- A numpy matrix of shape (n, m)\n",
    "    \n",
    "    Returns:\n",
    "    X -- The modified and normalised numpy matrix X\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INPUT YOUR CODE HERE ### (2 lines)\n",
    "    X_norm = np.linalg.norm(X, ord=2, axis=1, keepdims=True)\n",
    "    X = X/X_norm\n",
    "    ### END OF YOUR CODE SEGMENT ### \n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalised X.shape = (2, 3)\n",
      "normalised X = [[0.27 0.53 0.8 ]\n",
      " [0.46 0.57 0.68]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(\"normalised X.shape = {}\".format(normalise(X).shape))\n",
    "print(\"normalised X = {}\".format(normalise(X)))\n",
    "assert(np.sum(np.linalg.norm(normalise(X),axis=1))==2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">***Expected Output:***\n",
    ">\n",
    "> `normalised X.shape = (2, 3)\n",
    "normalised X = [[0.27 0.53 0.8 ]\n",
    " [0.46 0.57 0.68]]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important normalisation function used in multi-dimensional classification problems is called the softmax function. Formally if $x\\in \\mathbb{R}^{1\\times n}$, the softmax function is defined as\n",
    "\n",
    "$$\\mbox{softmax}(x) = \\left[\\frac{e^{x_1}}{\\sum_{i=1}^n e^{x_i}},\\frac{e^{x_2}}{\\sum_{i=1}^n e^{x_i}},\\ldots,\\frac{e^{x_n}}{\\sum_{i=1}^n e^{x_i}}\\right]$$ \n",
    "\n",
    "> <font color='darkgreen'>**Exercise 6:**</font> Implement the softmax function using numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    \"\"\"Softmax for each row of the input X of shape (n, m)\n",
    "\n",
    "    Argument:\n",
    "    X -- A numpy matrix of shape (n,m)\n",
    "\n",
    "    Returns:\n",
    "    S -- A numpy matrix of shape (n,m) equal to the softmax of X\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INPUT YOUR CODE HERE ### (3 lines)\n",
    "    X_exp = np.exp(X)\n",
    "    X_sum = np.sum(X_exp, axis=1, keepdims=True)\n",
    "    S = X_exp/X_sum\n",
    "    \n",
    "    \n",
    "    #S= np.exp(X) / np.sum(np.exp(X), axis=0) \n",
    "    ### END OF YOUR CODE SEGMENT ### \n",
    "    \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax = [[0.05 0.   0.95]\n",
      " [0.5  0.5  0.  ]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[3, 0, 6],[8, 8, 0]])\n",
    "print(\"softmax = {}\".format(softmax(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">***Expected Output:***\n",
    ">\n",
    ">`softmax = [[0.05 0.   0.95]\n",
    " [0.5  0.5  0.  ]]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "- You could do a sanity check and verify that each row sums up to 1 with numpy function `np.sum(softmax(X),1)`\n",
    "- The softmax function allows us to interpret each row element as a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "\n",
    "## B. Vectorisation ##\n",
    "\n",
    "Training deep learning models is generally performed on large datasets. To avoid severe performance bottlenecks, you must ensure your code runs efficiently. This is particularly important when using scripting languages such as Python where compiler optimisation is not available. One very important concept is called vectorisation. Evaluate and study the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.45 ms vs. 1.99 ms\n",
      "vectorised product is 15.3x faster!\n",
      "diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "x = [3, 8, 5, 0, 3, 9, 4, 0]\n",
    "y = [1, 8, 2, 7, 4, 5, 7, 2]\n",
    "\n",
    "### python outer product ###\n",
    "delta_t1 = time.time()\n",
    "for k in range(1000):\n",
    "    outer1 = np.zeros((len(x),len(y))) \n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(y)):\n",
    "            outer1[i,j] = x[i] * y[j]\n",
    "delta_t1 = time.time() - delta_t1\n",
    "\n",
    "### convert python array to np.array (row vector)\n",
    "x = np.array(x)\n",
    "x = x.reshape(1,np.prod(x.shape)) \n",
    "y = np.array(y)\n",
    "y = y.reshape(1,np.prod(y.shape))\n",
    "\n",
    "### numpy vectorised outer product ###\n",
    "delta_t2 = time.time()\n",
    "for k in range(1000):\n",
    "    outer2 = x.T @ y\n",
    "delta_t2 = time.time() - delta_t2\n",
    "\n",
    "print(\"{:.2f} ms vs. {:.2f} ms\".format(1000 * delta_t1, 1000 * delta_t2))\n",
    "print(\"vectorised product is {:.1f}x faster!\".format(delta_t1 / delta_t2))\n",
    "\n",
    "diff = np.sum(outer1-outer2)\n",
    "print(\"diff: \" + str(diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many linear operations such as the dot product of vectors can be expressed as matrix product. For example, if $x, y\\in \\mathbb{R}^{1\\times n}$, $x\\cdot y = x\\, y^T \\in \\mathbb{R}$ provides the dot product and $x\\otimes y=x^Ty \\in \\mathbb{R}^{n\\times n}$ gives the outer product. Study the code below carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=(1, 8)\n",
      "y.shape=(1, 8)\n"
     ]
    }
   ],
   "source": [
    "print(\"x.shape={}\".format(x.shape)) # (1x8) row vector\n",
    "print(\"y.shape={}\".format(x.shape)) # (1x8) row vector\n",
    "\n",
    "### vectorised dot product ###\n",
    "res = np.dot(x.flatten(),y.flatten())\n",
    "res1 = np.matmul(x,y.T).reshape(1)\n",
    "res2 = x @ y.T # preferred\n",
    "assert(res == res1)\n",
    "assert(res == res2)\n",
    "\n",
    "### vectorised outer product ###\n",
    "res = np.outer(x.flatten(),y.flatten())\n",
    "res1 = np.matmul(x.T,y)\n",
    "res2 = x.T @ y # preferred\n",
    "assert(np.sum(res-res1) == 0)\n",
    "assert(np.sum(res-res2) == 0)\n",
    "\n",
    "### vectorised element-wise multiplication ###\n",
    "res = np.multiply(x.flatten(),y.flatten())\n",
    "res1 = x * y # preferred\n",
    "assert(np.sum(res-res1) == 0)\n",
    "\n",
    "### matrix/vector product ###\n",
    "w = np.random.rand(2,x.shape[1]) # Random (2x8)\n",
    "res = np.dot(w,x.flatten())\n",
    "res1 = w @ x.T # preferred\n",
    "assert(np.sum(res-res1) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vectorized implementation is not only more elegant but also more efficient. This is particularly important for large matrices or vectors.\n",
    "\n",
    "Use `np.multiply()` or simply `*` to perform an element-wise multiplication. Use `np.matmul()` or simply `@` to compute the product of matrices. `.T` returns the matrix transpose.\n",
    "\n",
    "> <font color='darkgreen'>**Exercise 7:**</font> Let's now implement the $L_2$ loss function using numpy vectorised operations. The $L_2$ loss is an important performance measure for models in deep learning. A large loss means that your model predictions $\\hat{y}$ are poor and far away from the ground truth $y$. Model parameters are generally optimised using gradient descent in an attempt to minimise the loss.\n",
    ">\n",
    "> Formally the $L_2$ loss is defined as $L_2(y,\\hat{y})=\\sum_{i=1}^m (\\hat{y}^i-y^i)^2$\n",
    "> \n",
    "> There are several ways to implement the $L_2$. As a reminder, if $x \\in \\mathbb{R}^{1\\times n}$, then `np.dot(x,x)` = $\\sum_{i=1}^n x_i^{2} = x\\, x^T$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def L2(y,y_hat):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    y -- vector of size m (ground truth labels)\n",
    "    y_hat -- vector of size m (predicted labels)\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    loss -- L2 loss\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INPUT YOUR CODE HERE ### (1 line)\n",
    "    loss = np.sum(np.dot(y-y_hat, y-y_hat))\n",
    "    ### END OF YOUR CODE SEGMENT ### \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 = 0.19\n"
     ]
    }
   ],
   "source": [
    "y_hat = np.array([.8, 0.3, 0.9, .2, .1])\n",
    "y = np.array([1, 0, 1, 0, 0])\n",
    "print(\"L2 = {:.2f}\".format(L2(y,y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Expected Output:***\n",
    ">\n",
    "> `L2 = 0.19`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can define  the $L_1$ loss as $L_1(y,\\hat{y})=\\sum_{i=1}^m |\\hat{y}^i-y^i|$\n",
    "\n",
    "> <font color='darkgreen'>**Exercise 8:**</font> Implement the numpy vectorized version of the $L_1$ loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def L1(y,y_hat):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    y -- vector of size m (ground truth labels)\n",
    "    y_hat -- vector of size m (predicted labels)\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    loss -- L1 loss\n",
    "    \"\"\"\n",
    "    \n",
    "    ### INPUT YOUR CODE HERE ### (1 line)\n",
    "    loss = np.sum(np.abs(y-y_hat))\n",
    "    ### END OF YOUR CODE SEGMENT ### \n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 = 0.90\n"
     ]
    }
   ],
   "source": [
    "y_hat = np.array([.8, 0.3, 0.9, .2, .1])\n",
    "y = np.array([1, 0, 1, 0, 0])\n",
    "print(\"L1 = {:.2f}\".format(L1(y,y_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ***Expected Output:***\n",
    ">\n",
    "> `L1 = 0.90`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='darkblue'>**Take away:**</font>\n",
    "- numpy mathematical functions are applied to `np.array` element by element.<br> numpy provides many functions such `np.dot`, `np.sum`, `np.maximum`, `np.abs`, `np.multiply`...\n",
    "- use `np.reshape` to change the dimension of tensors and check tensor shapes with `np.shape`\n",
    "- numpy broadcasting mechanism is very useful however practice plenty to use it correctly\n",
    "- vectorisation provides compact code,  and elegance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- EOF --"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XHpfv",
   "launcher_item_id": "Zh0CU"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
